import os
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate

def main():
    """
    RAGã‚·ã‚¹ãƒ†ãƒ ã‚’å®Ÿè¡Œã™ã‚‹ãƒ¡ã‚¤ãƒ³é–¢æ•°
    """
    # --- 0. APIã‚­ãƒ¼ã®ç¢ºèª ---
    # Dev Containerã®ç’°å¢ƒå¤‰æ•°ã‹ã‚‰APIã‚­ãƒ¼ã‚’èª­ã¿è¾¼ã‚€
    api_key = os.environ.get("")
    if not api_key:
        print("ã‚¨ãƒ©ãƒ¼: ç’°å¢ƒå¤‰æ•° 'GOOGLE_API_KEY' ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return

    print("âœ… APIã‚­ãƒ¼ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")

    # --- 1. ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®èª­ã¿è¾¼ã¿ã¨åˆ†å‰² ---
    print("ğŸ”„ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™...")
    loader = PyPDFLoader("æ·±å±¤å­¦ç¿’ã¨IITã¨è‡ªç”±ã‚¨ãƒãƒ«ã‚®ãƒ¼åŸç†_.pdf")
    documents = loader.load()
    
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
    chunks = text_splitter.split_documents(documents)
    print(f"âœ… ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ {len(chunks)} å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã—ã¾ã—ãŸã€‚")

    # --- 2. ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã¨ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã®æ§‹ç¯‰ ---
    print("ğŸ”„ ãƒãƒ£ãƒ³ã‚¯ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã—ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æ§‹ç¯‰ã—ã¦ã„ã¾ã™...")
    embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001", google_api_key=api_key)
    vector_store = FAISS.from_documents(chunks, embeddings)
    print("âœ… ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã®æº–å‚™ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

    # --- 3. RAGãƒã‚§ãƒ¼ãƒ³ã®æ§‹ç¯‰ ---
    # LLMã¨ã—ã¦Gemini Proã‚’æº–å‚™
    llm = ChatGoogleGenerativeAI(model="gemini-pro", google_api_key=api_key, convert_system_message_to_human=True)

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’å®šç¾©
    prompt_template = """
    æä¾›ã•ã‚ŒãŸã€Œã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã€ã ã‘ã‚’å‚è€ƒã«ã—ã¦ã€ä»¥ä¸‹ã®ã€Œè³ªå•ã€ã«æ—¥æœ¬èªã§å…·ä½“çš„ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚
    ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã«ç­”ãˆãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€ã€Œãã®æƒ…å ±ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€ã¨å›ç­”ã—ã¦ãã ã•ã„ã€‚

    ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±:
    {context}

    è³ªå•: {question}
    """
    PROMPT = PromptTemplate(
        template=prompt_template, input_variables=["context", "question"]
    )

    # RAGãƒã‚§ãƒ¼ãƒ³ã‚’ä½œæˆ
    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=vector_store.as_retriever(),
        chain_type_kwargs={"prompt": PROMPT},
        return_source_documents=True
    )
    print("âœ… RAGãƒã‚§ãƒ¼ãƒ³ã®æº–å‚™ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

    # --- 4. è³ªå•å¿œç­”ã®å®Ÿè¡Œ ---
    print("\n--- è³ªå•å¿œç­”ã‚’é–‹å§‹ã—ã¾ã™ ---")
    question = "ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ã€è£½å“ã®ä¸»ãªæ©Ÿèƒ½ã¯ä½•ã§ã™ã‹ï¼Ÿ"
    
    print(f"è³ªå•: {question}")
    result = qa_chain.invoke({"query": question})

    print("\n--- å›ç­” ---")
    print(result["result"])
    
    print("\n--- å‚è€ƒã«ã—ãŸæƒ…å ±æº ---")
    for doc in result["source_documents"]:
        print(f"æŠœç²‹: {doc.page_content[:100]}...")

if __name__ == "__main__":
    main()