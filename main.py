import os
from dotenv import load_dotenv
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate

def main():
    """
    RAGã‚·ã‚¹ãƒ†ãƒ ã‚’å®Ÿè¡Œã™ã‚‹ãƒ¡ã‚¤ãƒ³é–¢æ•°
    """
    # --- 0. APIã‚­ãƒ¼ã®ç¢ºèª ---
    # .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿
    load_dotenv()
    key = os.environ.get("GOOGLE_API_KEY")
    if not key:
        print("âŒ ã‚¨ãƒ©ãƒ¼: ç’°å¢ƒå¤‰æ•° 'GOOGLE_API_KEY' ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        print("ğŸ“ .env ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã€GOOGLE_API_KEY=your_api_key ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        return

    print("âœ… APIã‚­ãƒ¼ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")

    # --- 1. ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®èª­ã¿è¾¼ã¿ã¨åˆ†å‰² ---
    print("ğŸ”„ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™...")
    try:
        loader = PyPDFLoader("æ·±å±¤å­¦ç¿’ã¨IITã¨è‡ªç”±ã‚¨ãƒãƒ«ã‚®ãƒ¼åŸç†_.pdf")
        documents = loader.load()
        
        if not documents:
            print("âŒ ã‚¨ãƒ©ãƒ¼: PDFãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‹ã€å†…å®¹ãŒç©ºã§ã™ã€‚")
            return
            
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
        chunks = text_splitter.split_documents(documents)
        print(f"âœ… ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ {len(chunks)} å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã—ã¾ã—ãŸã€‚")
        
    except FileNotFoundError:
        print("âŒ ã‚¨ãƒ©ãƒ¼: PDFãƒ•ã‚¡ã‚¤ãƒ« 'æ·±å±¤å­¦ç¿’ã¨IITã¨è‡ªç”±ã‚¨ãƒãƒ«ã‚®ãƒ¼åŸç†_.pdf' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return
    except Exception as e:
        print(f"âŒ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return

    # --- 2. ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã¨ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã®æ§‹ç¯‰ ---
    print("ğŸ”„ ãƒãƒ£ãƒ³ã‚¯ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã—ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æ§‹ç¯‰ã—ã¦ã„ã¾ã™...")
    try:
        embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001", google_api_key=key)
        vector_store = FAISS.from_documents(chunks, embeddings)
        print("âœ… ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã®æº–å‚™ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
    except Exception as e:
        print(f"âŒ ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        print("ğŸ’¡ APIã‚­ãƒ¼ãŒæ­£ã—ã„ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return

    # --- 3. RAGãƒã‚§ãƒ¼ãƒ³ã®æ§‹ç¯‰ ---
    print("ğŸ”„ RAGãƒã‚§ãƒ¼ãƒ³ã‚’æ§‹ç¯‰ã—ã¦ã„ã¾ã™...")
    try:
        # LLMã¨ã—ã¦Gemini Proã‚’æº–å‚™
        llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash-lite", google_api_key=key, convert_system_message_to_human=True)

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’å®šç¾©
        prompt_template = """
        æä¾›ã•ã‚ŒãŸã€Œã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã€ã ã‘ã‚’å‚è€ƒã«ã—ã¦ã€ä»¥ä¸‹ã®ã€Œè³ªå•ã€ã«æ—¥æœ¬èªã§å…·ä½“çš„ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚
        ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã«ç­”ãˆãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€ã€Œãã®æƒ…å ±ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€ã¨å›ç­”ã—ã¦ãã ã•ã„ã€‚

        ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±:
        {context}

        è³ªå•: {question}
        """
        PROMPT = PromptTemplate(
            template=prompt_template, input_variables=["context", "question"]
        )

        # RAGãƒã‚§ãƒ¼ãƒ³ã‚’ä½œæˆ
        qa_chain = RetrievalQA.from_chain_type(
            llm=llm,
            chain_type="stuff",
            retriever=vector_store.as_retriever(),
            chain_type_kwargs={"prompt": PROMPT},
            return_source_documents=True
        )
        print("âœ… RAGãƒã‚§ãƒ¼ãƒ³ã®æº–å‚™ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
    except Exception as e:
        print(f"âŒ RAGãƒã‚§ãƒ¼ãƒ³æ§‹ç¯‰ã‚¨ãƒ©ãƒ¼: {e}")
        return

    # --- 4. è³ªå•å¿œç­”ã®å®Ÿè¡Œ ---
    print("\n--- è³ªå•å¿œç­”ã‚’é–‹å§‹ã—ã¾ã™ ---")
    question = "ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ã€çµ±åˆæƒ…å ±ç†è«–ã¨ã¯ä½•ã§ã™ã‹?"
    
    print(f"è³ªå•: {question}")
    try:
        result = qa_chain.invoke({"query": question})

        print("\n--- å›ç­” ---")
        print(result["result"])
        

        def clean_text(text: str) -> str:
            # æ”¹è¡Œã‚„é€£ç¶šã‚¹ãƒšãƒ¼ã‚¹ã‚’é™¤å»ã—ã¦èª­ã¿ã‚„ã™ãã™ã‚‹
            import re
            # æ”¹è¡Œã‚’ã‚¹ãƒšãƒ¼ã‚¹ã«ç½®æ›
            text = text.replace("\n", " ")
            # è¤‡æ•°ã‚¹ãƒšãƒ¼ã‚¹ã¯1ã¤ã«
            text = re.sub(r"\s+", " ", text)
            # å‰å¾Œã®ç©ºç™½ã‚’å‰Šé™¤
            text = text.strip()
            return text

        # è³ªå•å¿œç­”çµæœã®å‡ºåŠ›éƒ¨åˆ†ã®ä¸€éƒ¨ã‚’ä¿®æ­£
        print("\n--- å‚è€ƒã«ã—ãŸæƒ…å ±æº ---")
        for i, doc in enumerate(result["source_documents"], 1):
            cleaned = clean_text(doc.page_content)
            print(f"{i}. æŠœç²‹: {cleaned[:300]}...")  # 300æ–‡å­—ã¾ã§è¡¨ç¤º

            
    except Exception as e:
        print(f"âŒ è³ªå•å¿œç­”ã‚¨ãƒ©ãƒ¼: {e}")
        return
        
    print("\nğŸ‰ RAGã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿè¡ŒãŒå®Œäº†ã—ã¾ã—ãŸï¼")

if __name__ == "__main__":
    main()